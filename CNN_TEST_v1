#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Mar 26 15:15:41 2018

@author: ighazi
"""
import torch
import torch.nn as nn
import torch.nn.functional as f
import numpy as np
import torch.optim as optim
from torch.autograd import Variable
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time
from models.Net import CNN
import sys, os



# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))


# get some random training images



"""This code is for creating a convolutional neural network classifier that 
will work with Pascal VOC to classify our images"""

resume= 'checkpoint.pth.tar'
global x,y

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)
start_time= time.time()
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


dataiter = iter(trainloader)
images, labels = dataiter.next()
net = CNN()
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9,weight_decay=5e-4)


if resume is not None:                                         
        if os.path.isfile(resume):
            print("Loading model and optimizer from checkpoint '{}'".format(resume))
            checkpoint = torch.load(resume)
            net.load_state_dict(checkpoint['state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer'])
            print("Loaded checkpoint '{}' (epoch)"                    
                  .format(resume, checkpoint['epoch']))
        else:
            print("No checkpoint found at '{}'".format(resume)) 

net.eval();
"""Testing our data"""
print("Here")
correct = 0
total = 0
for data in testloader:
    images, labels = data
    outputs = net(Variable(images))
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))


"""Classes Prediction Accuracy"""
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
for data in testloader:
    images, labels = data
    outputs = net(Variable(images))
    _, predicted = torch.max(outputs.data, 1)
    c = (predicted == labels).squeeze()
    for i in range(4):
        label = labels[i]
        class_correct[label] += c[i]
        class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))


tot_time= time.time()- start_time
print(tot_time)

























"""
#Defining a random input
x= Variable(torch.rand(1,1,32,32), requires_grad= True)
out= net(x)
print(net)
parameters= list(net.parameters())

print(parameters[0])

g= torch.randn(1,10)
net.zero_grad()
out.backward(torch.randn(1,10))
print(g)
        
Backpropagation"""

"""Backpropagation practice
input = Variable(torch.randn(1, 1, 32, 32))
out = net(input)
print(out)

net.zero_grad()
out.backward(torch.randn(1, 10))
print(out.grad)
target = Variable(torch.arange(1, 11))

optimizer = optim.SGD(net.parameters(), lr=0.01)

# in your training loop:
optimizer.zero_grad()   # zero the gradient buffers
output = net(input)
criterion = nn.MSELoss()
loss = criterion(output, target)
loss.backward(retain_graph=True)
print(loss)
optimizer.step() 
loss.backward()
print(loss)
optimizer.step()
"""